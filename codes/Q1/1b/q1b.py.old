import logging
import os
from os import path



import pandas as pd
import numpy as np
from datetime import datetime
from openpyxl import Workbook
from openpyxl import load_workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import PatternFill
from openpyxl.styles.differential import DifferentialStyle
from openpyxl.formatting.rule import Rule

class Q1b:


    combination_set=["PeriodKey","Category","Country","Subcategory","Segment"]

    def validate_expected_value(self,df,col_name,expected_values):
        logging.debug(f"validate_expected_value---> col_name= {col_name}")
        logging.debug(f"validate_expected_value---> expected_value= {expected_values}")
        err_df=df[~df[col_name].isin(expected_values)]
        logging.debug(f" ---> len err_df= {len(err_df)}") 
        logging.debug(f" ---> err_df={err_df.to_string()}")

        return err_df

    def rule_extra(self,df,col_expected_dict):
        logging.debug(f"rule_extra---> col_expected_dict= {col_expected_dict}")
        extra_list=[]
        all_df=None
        
        for key,val in col_expected_dict.items():
            err_df=self.validate_expected_value(df,key,val)          
            logging.debug(f"rule_extra---> err_df= {err_df}")  
            if len(err_df) >0:
                err_msg=f'Value at column {key} is not found in the list of expected values {val}'

                #err_df['Remarks'] = "err_msg"
                err_df.insert(0, 'Remarks', err_msg)
                extra_list.append(err_df)   
  
        if len(extra_list) > 0:
            all_err_df=pd.concat(extra_list)
            all_df=all_err_df.drop(columns=['Remarks'])
            logging.debug(f"rule_extra---> all_df= {all_df.to_string()}") 
            all_df.drop_duplicates(keep="first",inplace=True)


        remarks_list=[]
        for index,row in all_df.iterrows(): 
            logging.debug(f" ---> row= {row}")
            logging.debug(f" ---> index= {index}") 
            df_err=all_err_df
            for key in col_expected_dict:
                df_err=df_err[df_err[key] == row[key]]
            logging.debug(f"rule_extra---> FILTER df_err= {df_err.to_string()}")

            all_err = ','.join(df_err["Remarks"])
            logging.debug(f"rule_extra---> all_err= {all_err}")
            remarks_list.append(all_err)
            #row["Remarks"]=all_err
            #logging.debug(f"rule_extra---> row= {row}")            
            #all_df.loc[index, :] = row
            #logging.debug(f"rule_extra---> ADD REMARKS all_df= {all_df.to_string()}")

        if all_df is not None:
            all_df.insert(0, 'Remarks', remarks_list)

        logging.debug(f"rule_extra---> ADD REMARKS all_df= {all_df.to_string()}")
        return(all_df)      

    def rule_duplicate(self,df,unique_keys):
        logging.debug(f"rule_extra---> unique_keys= {unique_keys}")
   
        err_msg=f"duplicates for combination set {unique_keys}"
        err_df = df[df.duplicated(subset=unique_keys, keep='first')]
        if len(err_df) > 0:
            err_df.insert(0, 'Remarks', err_msg)
        
        logging.debug(f"rule_extra---> err_df= {err_df.to_string()}")
        return(err_df)

    def rule_sum(self,df,col_list,total):
        logging.debug(f"rule_sum---> col_list= {col_list}")
        df_new = df.copy()
        df_new["sum"]=0
        for col in col_list:
            df_new["sum"]=df_new["sum"] + df_new[col]

        logging.debug(f"rule_sum---> df_new= {df_new.to_string()}")    

        err_df = df_new[df_new['sum'] != 100]

        err_msg=f"The sum of values for these columns {col_list} should be {total}% for each combination set."

        if len(err_df) > 0:
            err_df.insert(0, 'Remarks', err_msg)
        
        logging.debug(f"rule_sum---> df= {df.to_string()}")
        logging.debug(f"rule_sum---> df_new= {df_new.to_string()}")
        logging.debug(f"rule_sum---> err_df= {err_df.to_string()}")

        return(err_df)

    def rule_range(self,df,col_list,min=None,max=None,inclusive=True):
        logging.debug(f"rule_range---> col_list= {col_list}")
        logging.debug(f"rule_range---> min= {min}")
        logging.debug(f"rule_range---> max= {max}")
        logging.debug(f"rule_range---> inclusive= {inclusive}")


        err_df_list=[]
        for col in col_list:
            if min is not None and max is not None:
                err_df = df[df[col] < min] if inclusive else df[df[col] <= min]
                max_df= df[df[col] > max] if inclusive else df[df[col] >= max]
                err_df = err_df+ max_df
            elif min is not None:
                err_df = df[df[col] < min] if inclusive else df[df[col] <= min]
            elif max is not None:
                err_df = df[df[col] > max] if inclusive else df[df[col] >= max]
            else:
                err_df=None

            if err_df is not None:    
                err_df_list.append(err_df)

        all_err_df=None
        if len(err_df_list)>0:
            all_err_df=pd.concat(err_df_list)
            logging.debug(f"rule_range---> all_err_df= {all_err_df.to_string()}") 

            err_msg=f"The range of values for each of these columns {col_list} should be "
            if min is not None and max is not None:
                err_msg=err_msg+f"between {min} and {max}, both inclusive."
            elif min is not None:
                err_msg=err_msg+f"more than {min}, inclusive."
            else:
                err_msg=err_msg+f"less than {max}, inclusive."

            all_err_df.insert(0, 'Remarks', err_msg)
        
        logging.debug(f"rule_range---> all_err_df= {all_err_df.to_string()}")
        return(all_err_df)

    def rule_logic_compare(self,df,col1,col2,compare_type="GT"):
        logging.debug(f"rule_logic_compare---> col1= {col1}")
        logging.debug(f"rule_logic_compare---> col2= {col2}")
        logging.debug(f"rule_logic_compare---> compare_type= {compare_type}")

        err_df=None
        err_df = df[df[col1] <  df[col2]] if compare_type=="GT" else err_df
        err_df = df[df[col1] >  df[col2]] if compare_type=="LT" else err_df
        err_df = df[df[col1] != df[col2]] if compare_type=="EQ" else err_df


        err_msg=""
        err_msg=f"{col1} value should always be higher than {col2} value" if compare_type=="GT" else err_msg
        err_msg=f"{col1} value should always be less than {col2} value" if compare_type=="LT" else err_msg
        err_msg=f"{col1} value should always be equal to {col2} value" if compare_type=="EQ" else err_msg

        if len(err_df) > 0:
            err_df.insert(0, 'Remarks', err_msg)
        
        logging.debug(f"rule_range---> err_df= {err_df.to_string()}")

        return(err_df)

    def rule_logic_total(self,df,total_col,total_col_val,sub_col,compare_type="GT"):
        logging.debug(f"rule_logic_total---> df= {df.to_string()}")        
        logging.debug(f"rule_logic_total---> total_col= {total_col}")
        logging.debug(f"rule_logic_total---> total_col_val= {total_col_val}")
        logging.debug(f"rule_logic_total---> sub_col= {sub_col}")
        logging.debug(f"rule_logic_total---> compare_type= {compare_type}")

        total_df=df[df[total_col] == total_col_val] 
        logging.debug(f"rule_logic_total---> total_df= {total_df.to_string()}")

        no_total_df=df[df[total_col] !=total_col_val] 
        logging.debug(f"rule_logic_total---> no_total_df.columns= {no_total_df.columns}")
        logging.debug(f"rule_logic_total---> no_total_df= {no_total_df.to_string()}")

        cols_to_sum = ["conversations","people","% positive","% negative","% neutral"]
        sum_cols = ["conversations_sum","people_sum","% positive_sum","% negative_sum","% neutral_sum"]

        agg_dict={'conversations': [np.sum],
        'people': [np.sum],
        '% positive': [np.sum],
        '% negative': [np.sum],
        '% neutral': [np.sum]       
        }
 
        group_cols=self.combination_set.copy()
        group_cols.remove(total_col)
        logging.debug(f"rule_logic_total---> group_cols= {group_cols}")
        groupby_df = no_total_df.groupby(group_cols).agg(agg_dict)
        logging.debug(f"rule_logic_total--->8888 groupby_df= {groupby_df.to_string()}")
        #groupby_df = no_total_df.groupby(['PeriodKey','Category','Country','Segment']).agg({'conversations': [np.sum]})
        #groupby_df = no_total_df.groupby(['PeriodKey','Category','Country','Segment']).agg([np.sum])
        logging.debug(f"rule_logic_total---> groupby_df.columns= {groupby_df.columns}")
        groupby_df.columns = sum_cols
        #groupby_df = groupby_df.reset_index()
        logging.debug(f"rule_logic_total---> groupby_df= {groupby_df.to_string()}")

        merge_df=pd.merge(total_df, groupby_df, on=group_cols)
        logging.debug(f"rule_logic_total---> merge_df= {merge_df.to_string()}")

        err_df_list=[]
        for index,col in enumerate(cols_to_sum):
            logging.debug(f"rule_logic_total---> index= {index}")
            logging.debug(f"rule_logic_total---> col= {col}")
            logging.debug(f"rule_logic_total---> sum_cols[index]= {sum_cols[index]}")
            err_df=merge_df[merge_df[col]<=merge_df[sum_cols[index]]]
            logging.debug(f"rule_logic_total---> err_df= {err_df.to_string()}")
            if len(err_df)>0:
                err_df_list.append(err_df)

        all_err_df=None
        if len(err_df_list)>0:
            all_err_df=pd.concat(err_df_list)

            err_msg=f"{total_col}=’Total’ should always be higher than other {total_col} values for the same combination set."
            all_err_df.insert(0, 'Remarks', err_msg)

            logging.debug(f"rule_logic_total---> all_err_df= {all_err_df.to_string()}")

        return(all_err_df)

    def rule_missing(self,df,col_name):
        logging.debug(f"rule_missing---> col_name= {col_name}")
        segment_list=["All", "16-23 years old", "24-39 years old", "40+ years old"]
        segment_list.sort()

        err_msg=f"There should always be four different segments available for each Subcategory, namely [Segment=’All’, ’16-23 years old’, ’24-39 years old’, ’40+ years old’]"
        
        copied_df=df.copy()

        #copied_df.sort_values(self.combination_set, ascending =True)
        #logging.debug(f"rule_missing---> copied_df= {copied_df}")

        unique_subcategories=copied_df.Subcategory.unique()
        logging.debug(f"rule_missing---> unique_subcategories= {unique_subcategories}")
 
        err_df_list=[]
        for val in unique_subcategories:
            subcategory_df=copied_df[copied_df["Subcategory"]==val]
            logging.debug(f"rule_missing---> subcategory_df= {subcategory_df}")
            unique_segments=subcategory_df.Segment.unique()
            logging.debug(f"rule_missing---> unique_segments= {unique_segments}")
            logging.debug(f"rule_missing---> segment_list= {segment_list}")
            unique_segments.sort()

            diff=list(set(unique_segments) - set(segment_list))
            logging.debug(f"rule_missing---> diff= {diff}")
            logging.debug(f"rule_missing---> len diff= {len(diff)}")

            if  len(diff)>0:
                err_df_list.append(subcategory_df)

        all_err_df=None
        if len(err_df_list)>0:
            all_err_df=pd.concat(err_df_list)
            all_err_df.insert(0, 'Remarks', err_msg)

            logging.debug(f"rule_missing---> all_err_df= {all_err_df.to_string()}")

        return(all_err_df)

    def output_excel(self,file_name, sheet_name, df,no_output_msg="no errors are found"):
        logging.debug(f"output_excel---> file_name= {file_name}")
        logging.debug(f"output_excel---> sheet_name= {sheet_name}")        


        try:
            workbook = load_workbook(filename=file_name)         
        except FileNotFoundError:
            workbook = Workbook()
            logging.debug(f"output_excel---> workbook= {workbook}")    

        sheet_list=workbook.sheetnames

        if sheet_name in sheet_list:
            sheet = workbook[sheet_name]
        else:
            sheet=workbook.create_sheet(sheet_name)

        #products_sheet = workbook["Products"]
        #products_sheet.title = "New Products"

        logging.debug(f"output_excel--->  workbook.sheetnames= { workbook.sheetnames}") 

        if df is not None and len(df)>0:
            for row in dataframe_to_rows(df, index=False, header=True):
                sheet.append(row)
        else:        
            sheet["A1"] = no_output_msg
             
        if "Sheet" in workbook.sheetnames:
            del_sheet = workbook['Sheet']
            workbook.remove(del_sheet)            

        workbook.save(filename=file_name)        

   #===========================================================================================
    # Load Data from csv files from local
    #===========================================================================================
    def load_data(self,dir,file_type="csv",move_file=False,skip_rows=0,skip_footer=0):
        logging.debug(f'load_data---> dir={dir}')
        logging.debug(f'load_data---> file_type={file_type}')
        logging.debug(f'load_data---> move_file={move_file}')        
        logging.debug(f'load_data---> skip_rows={skip_rows}')
        logging.debug(f'load_data---> skip_footer={skip_footer}')

        err_msg=None
        #get from local csv files
        df_dict={}
  
        with os.scandir(dir) as fileList:
            for file in fileList:
                full_path=f'{dir}\{file.name}'
                logging.debug(f'---> full_path={full_path}')
                logging.debug(f'---> path.isfile(full_path)={path.isfile(full_path)}') 
                logging.debug(f'---> os.path.splitext(full_path)[1].lower()={os.path.splitext(full_path)[1].lower()==".csv"}')                               
                #only load csv file
                if (path.isfile(full_path) and os.path.splitext(full_path)[1].lower()==f'.{file_type}'):    
                    logging.debug(f'---> TRUE TRUE!!!!')       
                    df = pd.read_csv(full_path, engine='python', skiprows=skip_rows, skipfooter=skip_footer)
                    logging.debug(f'---> df={df}')
                    #pd.read_csv(full_path, skiprows=17, skipfooter=1)

                    #clean data
                    df.fillna('', inplace=True) #e.g website can be blank

                    #store to list
                    df_dict[file.name]=df

        logging.debug(f'---> df_dict={df_dict}')

        if df_dict:
            if move_file:
                #move processed files to processed directory
                self.move_files(self.CSV_DIR,self.PROCESSED_CSV_DIR)
                err_msg=None
        else:
            err_msg=f"No {file_type} files to process"

        return (df_dict,err_msg)
    #===========================================================================================
    # #V2 Move all processed files to processed folder in Local dir
    #============================================================================================    
    def move_files(self,from_dir,to_dir):
        logging.debug(f"move_files ---> from_dir= {from_dir}")   
        logging.debug(f"move_files ---> to_dir= {to_dir}")   
        
        with os.scandir(from_dir) as fileList:
            for file in fileList:
                full_path=f'{from_dir}\{file.name}'
                logging.debug(f'---> full_path={full_path}')
                #only move csv file
                if (path.isfile(full_path) and os.path.splitext(full_path)[1].lower()==".csv"): 
                    logging.debug(f'Moving {file.name}')

                    original_file=fr'{from_dir}\{file.name}'
                    new_file=fr'{to_dir}\{file.name}'

                    os.rename(original_file,new_file)


#main
log_format="[ %(asctime)s - %(levelname)s - %(threadName)s - (%(name)s - %(filename)s - %(funcName)s(), line %(lineno)d)]: %(message)s"
logging.basicConfig(filename='q1b.log', filemode='w', level=logging.DEBUG,format=log_format)

print(os.getcwd())
cwd=os.getcwd()

Q_DIR=rf"{cwd}\Q1"
CSV_DIR=rf"{Q_DIR}\1b"
PROCESSED_CSV_DIR=rf"{CSV_DIR}\processed"
OUTPUT_CSV_DIR=rf"{CSV_DIR}\output"

q1b=Q1b()

(df_list,err_msg)=q1b.load_data(CSV_DIR)#TEST
logging.debug(f"parse ---> len(df_list): {len(df_list)}")

column_expected_dict={ 
    q1b.combination_set[0]:[1],
    q1b.combination_set[1]:["Technical Ability Test"],
    q1b.combination_set[2]:["Singapore"],
    q1b.combination_set[3]:["At home","In office","Total"],
    q1b.combination_set[4]:["All","16-23 years old","24-39 years old","40+ years old"]
}

filename="errors_remarks.xlsx"
sheet_name="errors"
output_list=[]

for key, df in df_list.items():
    logging.debug(f"---> key= {key}")
    logging.debug(f"---> df= {df}")


    #for index,row in df.iterrows(): 
    #    logging.debug(f" ---> row= {row}")
    #    logging.debug(f" ---> index= {index}")  
  
    #####(1) dups
    rule_duplicate_errors=q1b.rule_duplicate(df,q1b.combination_set)
    logging.debug(f" ---> rule_duplicate_errors= {rule_duplicate_errors.to_string()}")  

    output_list.append(rule_duplicate_errors)

    #####(2) missing
    rule_missing_errors=q1b.rule_missing(df,"Subcategory")
    logging.debug(f" ---> rule_missing_errors= {rule_missing_errors}") 
    output_list.append(rule_missing_errors) 

    #####(3) extra
    rule_extra_errors=q1b.rule_extra(df,column_expected_dict)
    logging.debug(f" ---> rule_extra_errors= {rule_extra_errors.to_string()}")  
 
    output_list.append(rule_extra_errors)    

    ######(4) logic - 3
    #logic1
    rule_total2_errors=q1b.rule_logic_total(df,"Segment","All","Subcategory",compare_type="GT")
    logging.debug(f" ---> rule_total2_errors= {rule_total2_errors}") 
    output_list.append(rule_total2_errors) 
 
    #logic2
    rule_total1_errors=q1b.rule_logic_total(df,"Subcategory","Total","Segment",compare_type="GT")
    logging.debug(f" ---> rule_total1_errors= {rule_total1_errors.to_string()}") 
    output_list.append(rule_total1_errors) 

    #logic 3
    col_list=["conversations", "people"]
    rule_logic1_errors=q1b.rule_logic_compare(df,col_list[0],col_list[1],compare_type="GT")
    logging.debug(f" ---> rule_logic1_errors= {rule_logic1_errors.to_string()}")  
    output_list.append(rule_logic1_errors) 

    #####(5) sum
    col_list=["% positive", "% negative", "% neutral"]
    rule_sum_errors=q1b.rule_sum(df,col_list,100)
    logging.debug(f" ---> rule_sum_errors= {rule_sum_errors.to_string()}") 

    output_list.append(rule_sum_errors)

    ######((6) range -2
    #range 1
    col_list=["% positive", "% negative", "% neutral"]
    rule_range1_errors=q1b.rule_range(df,col_list,min=0,max=100)
    logging.debug(f" ---> rule_range1_errors= {rule_range1_errors.to_string()}")
    output_list.append(rule_range1_errors) 

    #range 2
    col_list=["conversations", "people"]
    rule_range2_errors=q1b.rule_range(df,col_list,min=0)
    logging.debug(f" ---> rule_range2_errors= {rule_range2_errors.to_string()}") 
    output_list.append(rule_range2_errors) 


    #####concat all errror
    all_err_df=pd.concat(output_list, axis=0)

    #unique rows with combined err msg????

    q1b.output_excel(filename,sheet_name,all_err_df)
    
    
    #red_background = PatternFill(fgColor="00FF0000")
    #diff_style = DifferentialStyle(fill=red_background)
    #rule = Rule(type="expression", dxf=diff_style)
    #rule.formula = ["$H1<3"]
    #sheet.conditional_formatting.add("A1:O100", rule)



#The range of values for each of these columns [% positive, % negative, % neutral] should be between 0 and 100, both inclusive.
#range
#The range of values for each of these columns [conversations, people] should be more than 0.